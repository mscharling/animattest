{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residualer\n",
    "\n",
    "Vi fortsætter med at betragte datasættet\n",
    "\n",
    "$$\n",
    "\n",
    "    (x_1,y_1),(x_2,y_2),\\dots,(x_n,y_n),\n",
    "\n",
    "$$\n",
    "\n",
    "sammen med vores simple lineære model\n",
    "\n",
    "$$\n",
    "\n",
    "    f(x) = \\beta_0 + \\beta_1 x,\n",
    "\n",
    "$$\n",
    "\n",
    "*fitted* på vores data. I forrige afsnit kiggede vi på, hvordan vi kunne bruge de lodrette afstande fra vores datapunkter til linjen til at finde den rette linje, der bedst gik gennem vores datapunkter. Disse lodrette afstande kaldes for *residualer*. Vi vil benævne dem med $z_i$ for den $i$'te observation og de er givet som\n",
    "\n",
    "$$\n",
    "\n",
    "    z_i = y_i - f(x_i).\n",
    "\n",
    "$$ (eq:residualer)\n",
    "\n",
    "Omformer vi {eq}`eq:residualer`, så har vi at\n",
    "\n",
    "$$\n",
    "\n",
    "    y_i = f(x_i) + z_i.\n",
    "\n",
    "$$ (eq:model-med-residualer)\n",
    "\n",
    "Ligning {eq}`eq:model-med-residualer` fortæller os, at vi kan opdele vores observationer i to komponenter:\n",
    "\n",
    "1. $f(x_i)$: Dette er vores prædikterede værdi fra vores model $f(x) = \\beta_0 + \\beta_1 x$. Dette er punktet på linjen, som bedst beskriver sammenhængen mellem $x_i$ og $y_i$ ifølge vores model. \n",
    "2. $z_i$: Dette er vores residual (eller fejlen). Det er forskellen mellem den faktisk observerede værdi $y_i$ og den prædikterede værdi $f(x_i)$. Vi kalder det også fejlen, da den angiver hvor meget vores model afviger fra den faktiske observation.\n",
    "\n",
    "Denne opdeling er vigtig, da den viser, at hver observation $y_i$ består af den del, der kan forklares af den lineære model $f(x)$, og den del, der er uforklaret variation - residualerne $z_i$. \n",
    "\n",
    "For at forstå dette bedre kan du tænke på følgende: Vores datasæt kan være baseret på en lineær sammenhæng, der beskrives af forskriften $f(x)=\\beta_0 + \\beta_1 x$. Men i praksis vil der være *støj* eller tilfældige afvigelser i dataene, hvilket medfører, at de faktiske observationer $y_i$ ikke ligger præcist på den forudsagte linje. Denne støj er det, som residualerne fanger. Residualerne afspejler altså den uforklarede variation eller de små afvigelser fra den ideelle lineære sammenhæng, som skyldes støj, målefejl eller andre faktorer, der ikke er fanget af modellen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residualernes vigtige rolle\n",
    "\n",
    "Residualerne er helt centrale, når det kommer til at skulle evaluere, hvor god vores model er på vores data. Vi kræver en bestemt opførsel af residualerne for at konkludere, at en model er god til at beskrive sammenhængen i vores data.\n",
    "\n",
    "**Residualerne skal være så små som muligt**\n",
    "\n",
    "Dette er nærmest en selvfølge. Husk, residualerne kaldes også fejlen. Vi ønsker, at forskellen mellem de faktisk observerede værdier $y_i$ og de prædikterede værdier $f(x_i)$ er minimal. Desto mindre fejlen er, desto tættere på modellen befinder vores faktiske værdier sig. Det var præcis det idéen var bag mindste kvadraters metode. Her så vi, hvordan vi ved at minimere summen af kvadraterne på de lodrette afstande mellem datapunkterne og linjen, kunne bestemme den linje, der bedst gik gennem vores data. Disse lodrette afstande er jo netop residualerne. Med andre ord, så går mindste kvadraters metode ud på at minimere summen af kvadraterne på residualerne. Det kan vi også se, hvis vi indsætter {eq}`eq:residualer` i {eq}`eq:mindste-kvadraters-metode`\n",
    "\n",
    "$$\n",
    "\n",
    "    \\sum_{i=1}^n (y_i - f(x_i))^2 = \\sum_{i=1}^n z_i^2.\n",
    "\n",
    "$$\n",
    "\n",
    "I simpel lineær regression er det denne metode, som vi bruger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residualerne skal være tilfældige**\n",
    "\n",
    "Vi ønsker ikke, at der er et systematisk mønster i residualerne. Dette undersøger vi ved en visuel inspektion af residualerne i et residualplot. Et residualplot er blot et scatterplot, hvor vi plotter residualerne $z_i$ mod $x_i$ for alle vores datapunkter $i=1,2,\\dots,n$. Hvis der er et mønster i residualplottet, betyder det, at vores model ikke fanger alle strukturerne i dataene. Det vil oftest betyde, at vi har brug for en mere kompleks model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residualerne skal have konstant varians**\n",
    "\n",
    "Når vi betragter residualplottet, så skal der gerne være en symmetri i residualerne rundt om $x$-aksen. Vi vil gerne have, at residualerne varierer konstant rundt om $x$-aksen og størrelsen af variationen skal være nogenlunde ens på tværs af alle observationerne $x_i$. Dette kaldes homoskedacitet. Hvis variansen af residualerne stiger eller falder systematisk med $x_i$, så vil det kunne ses som en tragt-form i residualplottet. Er dette tilfældet, så vil vi muligvis have brug for en anden model eller tage højde for den varierende varians på en anden måde."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}